{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e904abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as tf\n",
    "import torchvision.models.segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af005d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = Path.home()/'Documents/datasets/drone_segmentation_dataset/dataset/original_images/'\n",
    "anns_folder = Path.home()/'Documents/datasets/drone_segmentation_dataset/dataset/label_images_semantic/'\n",
    "images = os.listdir(image_folder)\n",
    "anns = os.listdir(anns_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6e0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set some hyperparameters\n",
    "learning_rate=1e-5\n",
    "width = 6000  #Image width\n",
    "height = 4000 #Image height\n",
    "batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d62f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_files(file_list):\n",
    "    #The images labaled from '000' to '099' can be used for testing while those from '100' to '598' can be used \n",
    "    #for training the neural network\n",
    "    #First convert to integers\n",
    "    extension = file_list[0][3:]\n",
    "    file_list_numbers = []; training_data = []\n",
    "    test_data = []\n",
    "    for file in file_list:\n",
    "        if file[0] == '0':\n",
    "            test_data.append(file)\n",
    "            continue\n",
    "        name_int = int(file[:3])\n",
    "        file_list_numbers.append(name_int)\n",
    "    file_list_numbers = sorted(file_list_numbers)\n",
    "    for file in file_list_numbers:\n",
    "        file = str(file) + extension\n",
    "        training_data.append(file)\n",
    "    del extension,file_list_numbers\n",
    "    return training_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d526f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transform\n",
    "def data_transform():\n",
    "    image_transform=tf.Compose([\n",
    "                    tf.ToPILImage(),\n",
    "                    tf.Resize((height,width)), \n",
    "                    tf.ToTensor(),\n",
    "                    tf.Normalize((0.485, 0.456, 0.406), \n",
    "                                 (0.229, 0.224, 0.225))])\n",
    "    return image_transform\n",
    "def ann_transform():\n",
    "    ann_transform = tf.Compose([\n",
    "                    tf.ToPILImage(),\n",
    "                    tf.Resize((height,width)), \n",
    "                    tf.ToTensor()\n",
    "                    ])\n",
    "    return ann_transform\n",
    "Img_transform = data_transform()\n",
    "ANN_transform = ann_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d447c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100.jpg', '101.jpg']\n",
      "['100.png', '101.png']\n"
     ]
    }
   ],
   "source": [
    "training_images,testing_images = sort_files(images)\n",
    "training_anns,testing_anns = sort_files(anns)\n",
    "print(training_images[:2])\n",
    "print(training_anns[:2])\n",
    "def ReadRandomImage(): # First lets load random image and  the corresponding annotation\n",
    "    idx=np.random.randint(0,len(training_images)) # Select random image\n",
    "    Img = cv2.imread(os.path.join(image_folder,training_images[idx]))[:,:,0:3]\n",
    "    Ann = cv2.imread(os.path.join(anns_folder, training_anns[idx]),0)\n",
    "    AnnMap = np.zeros(Img.shape[0:2],np.float32)\n",
    "    for label in range(0,24):\n",
    "        AnnMap[Ann == label] = label\n",
    "    Img = Img_transform(Img)\n",
    "    AnnMap = ANN_transform(AnnMap)\n",
    "    return Img,AnnMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37ea34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(): # Load batch of images\n",
    "    images = torch.zeros([batch_size,3,height,width])\n",
    "    ann = torch.zeros([batch_size, height, width])\n",
    "    for i in range(batch_size):\n",
    "        images[i],ann[i]=ReadRandomImage()\n",
    "    return images, ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e254f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the device and the model of interest\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True) # Load net\n",
    "Net.classifier[4] = torch.nn.Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 3 classes\n",
    "Net=Net.to(device)\n",
    "optimizer=torch.optim.Adam(params=Net.parameters(),lr=learning_rate) # Create adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([5, 4000, 6000])\n"
     ]
    }
   ],
   "source": [
    "for itr in range(1): # Training loop\n",
    "   images,ann=load_batch() # Load taining batch\n",
    "   print(type(ann))\n",
    "   print(ann.size())\n",
    "   images=torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n",
    "   ann = torch.autograd.Variable(ann, requires_grad=False).to(device) # Load annotation\n",
    "   Pred=Net(images)['out'] # make prediction\n",
    "   Net.zero_grad()\n",
    "   criterion = torch.nn.CrossEntropyLoss() # Set loss function\n",
    "   Loss=criterion(Pred,ann.long()) # Calculate cross entropy loss\n",
    "   Loss.backward() # Backpropogate loss\n",
    "   optimizer.step() # Apply gradient descent change to weight\n",
    "   seg = torch.argmax(Pred[0], 0).cpu().detach().numpy()  # Get prediction classes\n",
    "   print(\"\\n\")\n",
    "   print(type(seg))\n",
    "   unique_values = np.unique(seg)\n",
    "   print(unique_values)\n",
    "   count_0 = np.count_nonzero(seg == 0)\n",
    "   count_1 = np.count_nonzero(seg == 1)\n",
    "   count_2 = np.count_nonzero(seg == 2)\n",
    "   print(count_0)\n",
    "   print(count_1)\n",
    "   print(count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe66ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
